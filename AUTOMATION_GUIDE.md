# NWU Protocol - Automation Guide

## ğŸ¤– Overview

This guide covers all the automation features that eliminate repetitive tasks and streamline your development workflow.

## ğŸš€ Quick Start

### First-Time Setup

1. **Install Automation Scripts**
   ```bash
   ./scripts/setup-automation.sh
   ```
   This will:
   - Make all scripts executable
   - Install Git pre-commit hooks
   - Create convenience aliases
   - Test all automation scripts

2. **Configure Environment**
   ```bash
   ./configure.sh
   ```
   Interactive wizard that:
   - Guides you through environment setup
   - Validates API keys
   - Generates secure secrets
   - Creates `.env` and `frontend/.env.local`

3. **Run Tests**
   ```bash
   ./test-all.sh
   ```
   Smart test runner with caching

---

## ğŸ“‹ Automation Features

### 1. ğŸ”§ Unified Test Runner

**Location:** `scripts/test-runner.sh` (alias: `./test-all.sh`)

**Features:**
- **Smart Caching**: Skips passing tests from last 5 minutes
- **Parallel Execution**: Runs independent tests simultaneously
- **Selective Testing**: Choose specific test categories
- **Clear Output**: Color-coded results with summary

**Usage:**
```bash
# Run all tests with caching
./test-all.sh

# Force run all tests (no cache)
./test-all.sh --no-cache

# Run specific categories
./test-all.sh infrastructure api

# Run tests sequentially with verbose output
./test-all.sh --sequential --verbose

# Show help
./test-all.sh --help
```

**Categories:**
- `infrastructure` - Docker, containers, services
- `health` - Service health checks
- `api` - Backend API endpoints
- `integration` - Service integrations

**Benefits:**
- â±ï¸ Saves 5-10 minutes per test run with caching
- ğŸš€ Parallel execution is 2-3x faster
- ğŸ¯ Selective testing when you know what changed
- ğŸ“Š Clear summary shows exactly what passed/failed

---

### 2. ğŸ¨ Configuration Wizard

**Location:** `scripts/config-wizard.sh` (alias: `./configure.sh`)

**Features:**
- **Interactive Prompts**: Step-by-step environment setup
- **Smart Defaults**: Suggests common values
- **API Key Validation**: Tests OpenAI keys before saving
- **Secure Secrets**: Auto-generates JWT secrets
- **Multi-Environment**: Creates both root and frontend configs

**Usage:**
```bash
# Run interactive wizard
./configure.sh

# Specify custom output paths
./scripts/config-wizard.sh .env.custom frontend/.env.production
```

**What It Configures:**
- PostgreSQL, MongoDB, Redis, RabbitMQ, IPFS
- OpenAI API key with validation
- JWT secret (auto-generated)
- Backend and frontend ports
- Environment type (development/production)

**Benefits:**
- â±ï¸ Saves 5-10 minutes per setup
- âœ… Reduces configuration errors
- ğŸ” Ensures secure defaults
- ğŸ¯ One command instead of editing 3+ files

---

### 3. ğŸ›¡ï¸ Enhanced Pre-Commit Hooks

**Location:** `scripts/pre-commit-hook.sh`

**Automatically runs before every commit:**

1. **Auto-Formatting**
   - Prettier for JS/TS/JSON/CSS/Markdown
   - Black for Python
   - Automatically stages formatted files

2. **Security Checks**
   - Detects hardcoded API keys
   - Catches secret patterns (AWS keys, GitHub tokens)
   - Blocks commits with secrets

3. **Quality Warnings**
   - Placeholder value detection
   - Debug statement warnings
   - Large file alerts (>10MB)

4. **Commit Message Validation**
   - Enforces Conventional Commits format
   - Examples: `feat(api): add endpoint`, `fix(ui): button color`

**Installation:**
```bash
# Installed automatically by setup-automation.sh
./scripts/setup-automation.sh

# Or manually
cp scripts/pre-commit-hook.sh .git/hooks/pre-commit
chmod +x .git/hooks/pre-commit
```

**Bypass (not recommended):**
```bash
git commit --no-verify
```

**Benefits:**
- ğŸ” Prevents secret leaks automatically
- âœ¨ Code always formatted consistently
- ğŸ“ Enforces commit message standards
- â±ï¸ Saves 5-15 minutes per PR in review cycles

---

### 4. ğŸ—„ï¸ Shared Service Registry

**Location:** `scripts/service-registry.sh`

**Central source of truth for:**
- Service names and descriptions
- Health check URLs
- Container names
- Port mappings
- Startup order

**Usage in Scripts:**
```bash
#!/bin/bash
source "$(dirname "$0")/service-registry.sh"

# Use shared logging
log_info "Starting services..."
log_success "All services healthy!"

# Check service health
if check_service_health "postgres"; then
    log_success "PostgreSQL is healthy"
fi

# Wait for service
wait_for_service "backend" 60
```

**Benefits:**
- ğŸ“¦ DRY principle - no duplication
- ğŸ”§ Easy maintenance - change once, update everywhere
- ğŸ¨ Consistent logging and output
- ğŸ” Reliable health checking

---

## ğŸ› ï¸ Advanced Usage

### Running Tests in CI/CD

```bash
# In your GitHub Actions workflow
- name: Run Tests
  run: ./test-all.sh --no-cache --sequential
```

### Custom Test Categories

Edit `scripts/test-runner.sh` to add custom test functions:

```bash
test_custom() {
    log_info "Running custom tests..."
    # Your test logic here
}

# Add to categories array
CATEGORIES=("infrastructure" "health" "api" "integration" "custom")
```

### Configuration Profiles

Create multiple environment configs:

```bash
# Development
./configure.sh .env.dev frontend/.env.dev

# Production
./configure.sh .env.prod frontend/.env.prod

# Switch environments
cp .env.prod .env
```

---

## ğŸ“Š Performance Improvements

| Task | Before | After | Savings |
|------|--------|-------|---------|
| Full test run | 10-15 min | 2-5 min | **70%** |
| Environment setup | 10-15 min | 2 min | **85%** |
| Pre-commit checks | Manual | Automatic | **100%** |
| Service health checks | Scattered | Centralized | **Maintainability** |

---

## ğŸ” Troubleshooting

### Test Runner Issues

**Problem:** Tests fail but services are running
```bash
# Clear test cache
rm -rf /tmp/nwu-test-cache
./test-all.sh --no-cache
```

**Problem:** Permission denied
```bash
chmod +x scripts/*.sh
```

### Configuration Wizard Issues

**Problem:** OpenAI key validation fails
- Check internet connectivity
- Verify key starts with `sk-`
- Use `--skip-validation` flag (add if needed)

**Problem:** .env file not created
- Check write permissions in directory
- Ensure script is run from repo root

### Pre-Commit Hook Issues

**Problem:** Hook not running
```bash
# Reinstall hook
./scripts/setup-automation.sh
```

**Problem:** False positive on secrets
- Add exception to `.gitignore`
- Use environment variables instead

---

## ğŸ’¡ Best Practices

1. **Run setup-automation.sh once per clone**
   ```bash
   git clone <repo>
   cd nwu-protocol
   ./scripts/setup-automation.sh
   ```

2. **Use configuration wizard for new environments**
   ```bash
   ./configure.sh
   ```

3. **Run test-all.sh before committing major changes**
   ```bash
   ./test-all.sh
   git commit -m "feat: major feature"
   ```

4. **Keep scripts up to date**
   ```bash
   git pull
   ./scripts/setup-automation.sh
   ```

---

## ğŸ¤ Contributing

### Adding New Automation

1. Create script in `scripts/` directory
2. Source `service-registry.sh` for shared utilities
3. Follow naming convention: `noun-verb.sh`
4. Add documentation to this file
5. Update `setup-automation.sh` if needed

### Modifying Existing Automation

1. Test changes thoroughly
2. Update documentation
3. Ensure backward compatibility
4. Follow existing code style

---

## ğŸ“š Additional Resources

- [Contributing Guide](CONTRIBUTING.md) - PR workflow
- [Build Standards](BUILD_STANDARDS.md) - CI/CD requirements
- [Coding Standards](CODING_STANDARDS.md) - Code style guide
- [Deployment Guide](DEPLOYMENT.md) - Production deployment

---

## ğŸ¯ What's Automated

### âœ… Fully Automated
- [x] Code formatting (Prettier, Black)
- [x] Pre-commit quality checks
- [x] Test execution and caching
- [x] Environment configuration
- [x] Secret detection
- [x] Service health monitoring

### ğŸ”„ Partially Automated
- [x] Test result caching (5 min TTL)
- [x] API key validation (requires internet)
- [x] Commit message validation

### ğŸ“‹ Manual (as designed)
- [ ] Pull request creation (use GitHub UI)
- [ ] Production deployments (require approval)
- [ ] Security incident response

---

## ğŸ†˜ Support

For issues or questions:
1. Check [troubleshooting](#-troubleshooting) section
2. Review script source code in `scripts/`
3. Open an issue on GitHub
4. Contact maintainers

---

*Last updated: February 2026*
